#!/usr/bin/env python3
"""
RotNet (ResNet-18 Mishç‰ˆ) è®­ç»ƒè„šæœ¬ - ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
"""
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split, Subset
from torchvision import transforms, models
from PIL import Image, ImageOps
import random
import os
from tqdm import tqdm

LEARNING_RATE = 3e-4
BATCH_SIZE = 32
NUM_EPOCHS = 30 
WEIGHT_DECAY = 1e-4
IMAGE_SIZE = 224
DROP_RATE = 0.5
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

IMAGE_DIR = './data/image/'
MODEL_SAVE_DIR = './model/'



def replace_relu_with_mish(model):
    """
    é€’å½’åœ°å°†æ‰€æœ‰ nn.ReLU å±‚æ›¿æ¢ä¸º nn.Mish å±‚ã€‚
    """
    for name, module in model.named_children():
        if len(list(module.children())) > 0:
            replace_relu_with_mish(module)
        if isinstance(module, nn.ReLU):
            setattr(model, name, nn.Mish())

# æ•°æ®é›†
class CustomImageDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        try:
            self.img_paths = [os.path.join(img_dir, fname) for fname in os.listdir(img_dir) if fname.lower().endswith(('png', 'jpg', 'jpeg'))]
        except FileNotFoundError:
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• '{img_dir}'ã€‚")
            self.img_paths = []
        if not self.img_paths:
            print(f"è­¦å‘Š: åœ¨ç›®å½• '{img_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ã€‚")
        else:
            print(f"åœ¨ç›®å½• '{img_dir}' ä¸­æ‰¾åˆ° {len(self.img_paths)} å¼ å›¾ç‰‡ã€‚")

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        try:
            image = Image.open(img_path).convert("RGB")
            image = ImageOps.exif_transpose(image)
            if self.transform:
                image = self.transform(image)
            return image, 0
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•åŠ è½½æˆ–å¤„ç†å›¾ç‰‡ {img_path}ã€‚é”™è¯¯ä¿¡æ¯: {e}")
            return torch.zeros((3, IMAGE_SIZE, IMAGE_SIZE)), 0

class RandomRotation:
    def __init__(self):
        self.angles = [0, 90, 180, 270]

    def __call__(self, img):
        angle_choice = random.choice(self.angles)
        rotated_img = img.rotate(angle_choice, expand=True)
        label = self.angles.index(angle_choice)
        return rotated_img, label

class RotationDataset(Dataset):
    def __init__(self, underlying_dataset, final_transform=None):
        self.underlying_dataset = underlying_dataset
        self.rotation_transform = RandomRotation()
        self.final_transform = final_transform

    def __len__(self):
        return len(self.underlying_dataset)

    def __getitem__(self, idx):
        original_img, _ = self.underlying_dataset[idx]
        rotated_img, rotation_label = self.rotation_transform(original_img)
        if self.final_transform:
            final_img = self.final_transform(rotated_img)
        return final_img, torch.tensor(rotation_label, dtype=torch.long)


# æ•°æ®å¢å¼º è‡ªå·±çš„æ•°æ®é›†å¤ªè–„å¼±äº†ï¼Œä¸å¢å¼ºæ•ˆæœä¸å¥½
train_base_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE + 20, IMAGE_SIZE + 20)),
    transforms.RandomCrop(IMAGE_SIZE),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),
    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.RandomHorizontalFlip(p=0.5),
])

val_base_transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
])

final_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# åŠ è½½å’Œå‡†å¤‡æ•°æ® 
underlying_train_dataset = CustomImageDataset(img_dir=IMAGE_DIR, transform=train_base_transform)
underlying_val_dataset = CustomImageDataset(img_dir=IMAGE_DIR, transform=val_base_transform)

if len(underlying_train_dataset) == 0:
    raise ValueError(f"é”™è¯¯: åœ¨ '{IMAGE_DIR}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ã€‚")

train_size = int(0.8 * len(underlying_train_dataset))
val_size = len(underlying_train_dataset) - train_size
generator = torch.Generator().manual_seed(42)
train_indices, val_indices = random_split(range(len(underlying_train_dataset)), [train_size, val_size], generator=generator)

train_subset = Subset(underlying_train_dataset, train_indices)
val_subset = Subset(underlying_val_dataset, val_indices)
print(f"æ•°æ®é›†å·²åˆ†å‰²: {len(train_subset)} å¼ ç”¨äºè®­ç»ƒ, {len(val_subset)} å¼ ç”¨äºéªŒè¯ã€‚")

train_dataset = RotationDataset(train_subset, final_transform=final_transform)
val_dataset = RotationDataset(val_subset, final_transform=final_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

# æ¨¡å‹å®šä¹‰
class RotationPredictionModel(nn.Module):
    def __init__(self, num_classes=4):
        super(RotationPredictionModel, self).__init__()
        self.encoder = models.resnet18(weights='IMAGENET1K_V1')
        num_features = self.encoder.fc.in_features
        self.encoder.fc = nn.Identity()
        
        # æ ¹æ®æ˜¯å¦æµ‹è¯•è¿‡æ‹Ÿåˆæ¥è°ƒæ•´Dropoutç‡
        dropout_rate = DROP_RATE
        print(f"åˆ†ç±»å¤´Dropoutç‡è®¾ç½®ä¸º: {dropout_rate}")
        
        self.classifier = nn.Sequential(
            nn.Linear(num_features, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        features = self.encoder(x)
        outputs = self.classifier(features)
        return outputs

# --- 6. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ---
model = RotationPredictionModel(num_classes=4).to(DEVICE)
replace_relu_with_mish(model)

criterion = nn.CrossEntropyLoss()
# æ ¹æ®æ˜¯å¦æµ‹è¯•è¿‡æ‹Ÿåˆæ¥è°ƒæ•´æƒé‡è¡°å‡
wd = WEIGHT_DECAY
print(f"ä¼˜åŒ–å™¨æƒé‡è¡°å‡è®¾ç½®ä¸º: {wd}")
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=wd)

# ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)

# è®­ç»ƒå’ŒéªŒè¯
best_val_acc = 0.0
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

for epoch in range(NUM_EPOCHS):
    model.train()
    running_loss = 0.0
    correct_train = 0
    total_train = 0

    print(f"\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---")
    progress_bar = tqdm(train_loader, desc="è®­ç»ƒä¸­", colour="green")
    for images, labels in progress_bar:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()
        
        progress_bar.set_postfix(loss=loss.item())

    train_loss = running_loss / len(train_loader)
    train_acc = 100 * correct_train / total_train
    print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")

    model.eval()
    running_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        progress_bar = tqdm(val_loader, desc="éªŒè¯ä¸­", colour="cyan")
        for images, labels in progress_bar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()

    val_loss = running_loss / len(val_loader)
    val_acc = 100 * correct_val / total_val
    print(f"éªŒè¯æŸå¤±: {val_loss:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")

    # åŠ¨æ€è°ƒæ•´æ›´æ–°å­¦ä¹ ç‡
    # CosineAnnealingLRåœ¨æ¯ä¸ªepochåè°ƒç”¨step()ï¼Œæ— éœ€å‚æ•°
    scheduler.step()
    print(f"å½“å‰å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.6f}")

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        best_model_path = os.path.join(MODEL_SAVE_DIR, "mydata_rotnet_mish.pth")
        torch.save(model.state_dict(), best_model_path)
        print(f"ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%ã€‚æ¨¡å‹å·²ä¿å­˜è‡³: {best_model_path}")


print("\nè®­ç»ƒå®Œæˆ!")
print(f"æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æœ€ä½³çš„éªŒè¯å‡†ç¡®ç‡ä¸º: {best_val_acc:.2f}%")

# ä¿å­˜æœ€åä¸€è½®è®­ç»ƒçš„encoderç”¨äºäºŒé˜¶æ®µçš„åˆ†ç±»å™¨è®­ç»ƒ
print("\næ­£åœ¨æå–å¹¶ä¿å­˜æœ€ç»ˆçš„ Encoder æƒé‡ä»¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡")
ENCODER_OUTPUT_PATH = "./model/mydata_rotnet_mish_encoder.pth"
torch.save(model.encoder.state_dict(), ENCODER_OUTPUT_PATH)
print(f"Encoder æƒé‡å·²ä¿å­˜è‡³: '{ENCODER_OUTPUT_PATH}'")
